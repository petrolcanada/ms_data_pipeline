# Complete Data Transfer Workflow

End-to-end guide for transferring data from Snowflake to PostgreSQL across network boundaries.

---

## **Overview**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SNOWFLAKE SIDE (VPN)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â”‚ 1. Extract Metadata
    â”‚    python scripts/extract_metadata.py --all
    â”‚    â†’ metadata/schemas/*.json
    â”‚    â†’ metadata/ddl/*.sql
    â”‚
    â”‚ 2. Export Data
    â”‚    python scripts/export_data.py --all
    â”‚    â†’ D:/snowflake_exports/table_name/*.parquet.enc
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MANUAL TRANSFER                           â”‚
â”‚  Copy files from Snowflake server to PostgreSQL server      â”‚
â”‚  - metadata/ folder                                          â”‚
â”‚  - config/tables.yaml                                        â”‚
â”‚  - D:/snowflake_exports/ â†’ E:/postgres_imports/             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  POSTGRESQL SIDE (External)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â”‚ 3. Create Tables
    â”‚    python scripts/create_tables.py --all
    â”‚    â†’ Creates tables in PostgreSQL
    â”‚
    â”‚ 4. Import Data
    â”‚    python scripts/import_data.py --all
    â”‚    â†’ Loads data from encrypted files
    â”‚
    â–¼
   DONE!
```

---

## **Phase 1: Metadata (Snowflake Side)**

### **Step 1.1: Extract Metadata**

```bash
# Extract table schemas and generate DDL
python scripts/extract_metadata.py --all
```

**Output:**
```
metadata/
â”œâ”€â”€ schemas/
â”‚   â”œâ”€â”€ financial_data_metadata.json
â”‚   â””â”€â”€ market_prices_metadata.json
â””â”€â”€ ddl/
    â”œâ”€â”€ financial_data_create.sql
    â””â”€â”€ market_prices_create.sql
```

**What this does:**
- âœ… Connects to Snowflake
- âœ… Extracts table schemas
- âœ… Maps Snowflake types to PostgreSQL types
- âœ… Generates CREATE TABLE DDL scripts
- âœ… Saves metadata as JSON

---

## **Phase 2: Data Export (Snowflake Side)**

### **Step 2.1: Export Data**

```bash
# Export all tables
python scripts/export_data.py --all

# Or export specific table
python scripts/export_data.py --table financial_data
```

**Prompts:**
```
Enter encryption password: ********
Confirm password: ********
```

**Output:**
```
D:/snowflake_exports/
â”œâ”€â”€ financial_data/
â”‚   â”œâ”€â”€ data_chunk_001.parquet.enc
â”‚   â”œâ”€â”€ data_chunk_002.parquet.enc
â”‚   â”œâ”€â”€ data_chunk_003.parquet.enc
â”‚   â””â”€â”€ manifest.json
â””â”€â”€ market_prices/
    â”œâ”€â”€ data_chunk_001.parquet.enc
    â””â”€â”€ manifest.json
```

**What this does:**
- âœ… Extracts data from Snowflake in chunks
- âœ… Compresses data (Parquet + zstd)
- âœ… Encrypts files (AES-256-GCM)
- âœ… Generates manifest with checksums
- âœ… Saves to local directory

---

## **Phase 3: Manual Transfer**

### **Step 3.1: Copy Files to PostgreSQL Server**

**Files to transfer:**
```
Source (Snowflake server):
â”œâ”€â”€ metadata/                    â†’ Copy entire folder
â”œâ”€â”€ config/tables.yaml           â†’ Copy file
â””â”€â”€ D:/snowflake_exports/        â†’ Copy entire folder

Destination (PostgreSQL server):
â”œâ”€â”€ metadata/                    â†’ Same location
â”œâ”€â”€ config/tables.yaml           â†’ Same location
â””â”€â”€ E:/postgres_imports/         â†’ Configured in .env
```

**Transfer methods:**
- USB drive
- Network share
- SCP/SFTP
- Cloud storage (encrypted)

**Verification:**
```bash
# On PostgreSQL server, verify files exist
ls metadata/ddl/
ls metadata/schemas/
ls E:/postgres_imports/financial_data/
```

---

## **Phase 4: Create Tables (PostgreSQL Side)**

### **Step 4.1: Create All Tables**

```bash
# Create all tables from DDL files
python scripts/create_tables.py --all
```

**What this does:**
- âœ… Reads config/tables.yaml
- âœ… Loops through all tables
- âœ… Checks if DDL files exist
- âœ… Creates tables if they don't exist
- âœ… Verifies table structure
- âœ… Shows summary

**Output:**
```
======================================================================
Creating All Tables from config/tables.yaml
======================================================================

ğŸ“‹ Found 2 tables to create:
   - financial_data
   - market_prices

======================================================================
Creating Table: financial_data
======================================================================
âœ… Found metadata: financial_data_metadata.json
âœ… Found DDL: financial_data_create.sql

ğŸ”„ Creating table...
âœ… Table created successfully!
   Schema: public
   Table: financial_data
   Columns: 50

ğŸ” Verifying table structure...
âœ… Table structure verified!
   Snowflake columns: 50
   PostgreSQL columns: 50

ğŸ“Š Table info:
   Rows: 0
   Size: 8192 bytes

======================================================================
TABLE CREATION SUMMARY
======================================================================
Total tables: 2
âœ… Successful: 2
âŒ Failed: 0

ğŸ“‹ Results:
   âœ… financial_data: success
   âœ… market_prices: success
======================================================================
```

### **Step 4.2: Create Single Table (Optional)**

```bash
# Create specific table
python scripts/create_tables.py --table financial_data
```

### **Step 4.3: Recreate Tables (Optional)**

```bash
# Drop and recreate all tables
python scripts/create_tables.py --all --drop-existing
```

---

## **Phase 5: Import Data (PostgreSQL Side)**

### **Step 5.1: Import All Data**

```bash
# Import all tables
python scripts/import_data.py --all
```

**Prompts:**
```
Enter decryption password: ********
```

**What this does:**
- âœ… Reads manifest files
- âœ… Decrypts data files
- âœ… Verifies checksums
- âœ… Loads data to PostgreSQL
- âœ… Verifies row counts
- âœ… Cleans up temporary files

**Output:**
```
======================================================================
IMPORTING TABLE: financial_data
======================================================================

ğŸ“‹ Manifest loaded:
   Export date: 2024-01-15T10:30:00Z
   Total rows: 1,234,567
   Total chunks: 3

ğŸ”„ Processing 3 chunks...

ğŸ“¦ Chunk 1/3:
   File: data_chunk_001.parquet.enc
   Rows: 500,000
   ğŸ”“ Decrypting...
   âœ… Verifying checksum...
   ğŸ“¥ Loading to PostgreSQL...
   âœ… Loaded 500,000 rows

ğŸ“¦ Chunk 2/3:
   ...

ğŸ” Verifying row count...
âœ… Row count verified: 1,234,567 rows

ğŸ—‘ï¸  Cleaning up temporary files...
âœ… Removed 3 temporary files

ğŸ“Š Table information:
   Rows: 1,234,567
   Size: 125 MB

======================================================================
âœ… IMPORT COMPLETE!
======================================================================
ğŸ“Š Total: 1,234,567 rows loaded
ğŸ“ Table: public.financial_data
ğŸ’¾ Size: 125 MB
ğŸ’¾ Encrypted files kept as backup in: E:/postgres_imports/financial_data
======================================================================
```

### **Step 5.2: Import Single Table (Optional)**

```bash
# Import specific table
python scripts/import_data.py --table financial_data
```

### **Step 5.3: Truncate Before Import (Optional)**

```bash
# Clear table and reload
python scripts/import_data.py --table financial_data --truncate
```

---

## **Complete Command Reference**

### **Snowflake Side:**
```bash
# 1. Extract metadata
python scripts/extract_metadata.py --all

# 2. Export data
python scripts/export_data.py --all
```

### **Manual Transfer:**
```bash
# Copy files to PostgreSQL server
# (Use your preferred method)
```

### **PostgreSQL Side:**
```bash
# 3. Create tables
python scripts/create_tables.py --all

# 4. Import data
python scripts/import_data.py --all
```

---

## **Verification**

### **After Table Creation:**
```bash
# List tables
psql -h localhost -p 50211 -U postgres -d postgres -c "\dt public.*"

# Check table structure
psql -h localhost -p 50211 -U postgres -d postgres -c "\d public.financial_data"
```

### **After Data Import:**
```bash
# Check row count
psql -h localhost -p 50211 -U postgres -d postgres -c "SELECT COUNT(*) FROM public.financial_data;"

# Check sample data
psql -h localhost -p 50211 -U postgres -d postgres -c "SELECT * FROM public.financial_data LIMIT 10;"
```

---

## **Troubleshooting**

### **Metadata Issues:**
```bash
# If metadata files are missing
python scripts/extract_metadata.py --all

# Verify files exist
ls metadata/ddl/
ls metadata/schemas/
```

### **Table Creation Issues:**
```bash
# Test PostgreSQL connection
python test_postgres.py

# Check if table already exists
psql -h localhost -p 50211 -U postgres -d postgres -c "\dt public.*"

# Drop and recreate
python scripts/create_tables.py --table financial_data --drop-existing
```

### **Data Import Issues:**
```bash
# Verify encrypted files exist
ls E:/postgres_imports/financial_data/

# Check manifest
cat E:/postgres_imports/financial_data/manifest.json

# Test with single table
python scripts/import_data.py --table financial_data
```

---

## **Best Practices**

### **Security:**
1. âœ… Use strong encryption password (16+ characters)
2. âœ… Store password securely (password manager)
3. âœ… Don't commit password to git
4. âœ… Keep encrypted files as backup
5. âœ… Delete decrypted files after import (automatic)

### **Performance:**
1. âœ… Adjust chunk size based on table size
2. âœ… Use zstd compression for best ratio
3. âœ… Transfer during off-hours
4. âœ… Verify checksums (automatic)

### **Workflow:**
1. âœ… Test with one table first
2. âœ… Verify row counts match
3. âœ… Check sample data
4. âœ… Then process all tables
5. âœ… Keep logs for audit trail

---

## **Summary**

| Phase | Location | Command | Output |
|-------|----------|---------|--------|
| 1. Metadata | Snowflake | `extract_metadata.py --all` | metadata/*.json, *.sql |
| 2. Export | Snowflake | `export_data.py --all` | D:/snowflake_exports/*.enc |
| 3. Transfer | Manual | Copy files | E:/postgres_imports/*.enc |
| 4. Create Tables | PostgreSQL | `create_tables.py --all` | Tables in PostgreSQL |
| 5. Import | PostgreSQL | `import_data.py --all` | Data in PostgreSQL |

**Total time:** Depends on data size (typically 1-4 hours for large datasets)

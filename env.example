# Snowflake Connection (VPN Side)
# Use your full email as username
SNOWFLAKE_USER=PETER.LI@CI.COM

# Account identifier - use organizational format (orgname-accountname)
# Example: CIX-CIX (NOT CIX-CIX.ca-central-1)
SNOWFLAKE_ACCOUNT=CIX-CIX

# Warehouse name
SNOWFLAKE_WAREHOUSE=CIGAM_PRD_ANALYTICSSPECIALIST_DNA_WH

# Database and Schema
SNOWFLAKE_DATABASE=CIGAM_PRD_RL
SNOWFLAKE_SCHEMA=MORNINGSTAR_MAIN

# Role - REQUIRED for SSO authentication
SNOWFLAKE_ROLE=CIGAM_PRD_SNOWFLAKE_ANALYTICSSPECIALIST_DNA_FR

# Snowflake Authentication Method
# Options: password, sso, key_pair, oauth
SNOWFLAKE_AUTH_METHOD=sso

# Optional: Region (usually not needed with new account format)
# SNOWFLAKE_REGION=ca-central-1

# For password authentication (if not using SSO)
# SNOWFLAKE_PASSWORD=your_password

# For key pair authentication (if using)
# SNOWFLAKE_PRIVATE_KEY_PATH=/path/to/private_key.p8
# SNOWFLAKE_PRIVATE_KEY_PASSPHRASE=your_passphrase

# PostgreSQL Connection (External Side)
# For local development, use your local PostgreSQL instance
POSTGRES_HOST=localhost
POSTGRES_PORT=50211
POSTGRES_DATABASE=postgres
POSTGRES_USER=postgres
POSTGRES_PASSWORD=your-password

# Optional: Redis for Celery (if using background tasks)
REDIS_URL=redis://localhost:6379/0

# API Configuration
API_SECRET_KEY=your_secret_key_here
API_HOST=0.0.0.0
API_PORT=8000

# Logging
LOG_LEVEL=INFO

# Data Export/Import Settings
# Snowflake side - where to save exported data
EXPORT_BASE_DIR=D:/snowflake_exports

# PostgreSQL side - where to read imported data
IMPORT_BASE_DIR=E:/postgres_imports

# Encryption settings
# IMPORTANT: Set a strong encryption password for data and metadata encryption
# This password is used to encrypt/decrypt all exported data and metadata files
ENCRYPTION_PASSWORD=your_secure_password_here
KEY_DERIVATION_ITERATIONS=100000

# Obfuscation settings (default: enabled)
# Set to false to disable name obfuscation
OBFUSCATE_NAMES=true

# Compression
COMPRESSION_TYPE=zstd
COMPRESSION_LEVEL=15  # Higher level = better compression (1-22, default 3, recommended 15 for huge datasets)
CHUNK_SIZE=100000